{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "bdry_loss_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZAJmklfbbl-"
      },
      "source": [
        "# mount google drive to save results\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zasbcq5pMn2C"
      },
      "source": [
        "# THEORY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr1ZVwe_1bzJ"
      },
      "source": [
        "based on \n",
        "\n",
        "[H. Kervadeca, J. Bouchtibaa, C. Desrosiersa, E. Grangera, J. Dolza, I. Ben Ayed, \"Boundary loss for highly unbalanced segmentation\".](http://proceedings.mlr.press/v102/kervadec19a/kervadec19a.pdf)\n",
        "\n",
        "[D. Karimi and S. E. Salcudean, \"Reducing the Hausdorff Distance in Medical Image Segmentation With Convolutional Neural Networks\".](https://arxiv.org/pdf/1904.10030v1.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_koqoUp1bzV"
      },
      "source": [
        "$G$ - true mask, $S$ - predicted mask, $\\Delta S = S\\Delta G=(S\\setminus G)\\cup (G\\setminus S)$ - the region of mismatch.\n",
        "\n",
        "$G,\\ S\\subset\\Omega$, $\\Omega$ - the whole channel.\n",
        "\n",
        "\\begin{equation*}\n",
        "dist_k(\\partial G,\\partial S) = \\left(\\int_{\\partial G}\\|y_{\\partial S}(p) - p\\|^k\\,dp\\right)^\\frac{1}{k},\n",
        "\\end{equation*}\n",
        "where $\\|\\cdot\\|$ is Euclidian norm (could choose a different one). $y_{\\partial S}(p)$ - the closest point on $\\partial S$ along the normal vector $n_p$ to $\\partial G$. \n",
        "\n",
        "$D_G(q)=dist(q,\\partial G)= \\inf_{x\\in \\partial G}\\|q-x\\|$ - distance from the point $q$ to $\\partial G$. \n",
        "\n",
        "Parametrizing the segment $[p,y_{\\partial S}(p)]$ \n",
        "\\begin{cases}\n",
        "q = r(\\lambda): = p + \\lambda (y_{\\partial S}(p) - p),\\ \\lambda \\in [0,1],\\\\\n",
        "dq = \\|r'(\\lambda)\\|\\,d\\lambda = \\|y_{\\partial S}(p) - p\\|d\\lambda,\n",
        "\\end{cases}\n",
        "we get\n",
        "\n",
        "\\begin{multline*}\n",
        "\\int_p^{y_{\\partial_S}(p)}D^k_G(q) dq = \\int_p^{y_{\\partial_S}(p)}\\|q-p\\|^k dq =\n",
        "\\int_0^1\\lambda^k \\|p-y_{\\partial S}(p)\\|^k \\|p-y_{\\partial S}(p)\\| d\\lambda = \\frac{1}{k+1}\\|p-y_{\\partial S}(p)\\|^{k+1}.\n",
        "\\end{multline*}\n",
        "\n",
        "\n",
        "We have\n",
        "\\begin{multline*}\n",
        "(dist_k(\\partial G, \\partial S))^k = \\int_{\\partial G}\\|p - y_{\\partial_S}(p)\\|^k\\,dp = k\\int_{\\partial G}\\int_p^{y_{\\partial_S}(p)}D^{k-1}_G(q)\\,dq\\,dp =\\\\\n",
        " |iterated\\ to\\ double\\ integral|\\leq k\\int_{\\Delta S}D^{k-1}_G(x)\\,dx.\n",
        "\\end{multline*}\n",
        "\n",
        "<b>Rem 1</b> Actually, the above transition from iterated integral to double integral is a neat point. The funny thing is that the difference between these integrals depends on the smoothness of the bdry $G$. They seem to coincide for smooth $G$ but not in general case. The sign of inequality and how different those integrals could be is explained in the picture below\n",
        "\n",
        "[![Iterated vs Double Integral](https://raw.githubusercontent.com/antonsavostianov/bdry_loss/blob/main/iter_vs_double.jpg)](https://github.com/antonsavostianov/bdry_loss)\n",
        "\n",
        "The loss that we implement corresponds to the double integral. And the good news is that, as seen from the picture, the double integral is more appropriate for our purposes =) With some abuse of notations, from now on, our $dist_k(\\partial G,\\partial S)$ refers to the double integral, that is \n",
        "\\begin{equation*}\n",
        "(dist_k(\\partial G, \\partial S))^k = k\\int_{\\Delta S}D^{k-1}_G(x)\\,dx.\n",
        "\\end{equation*}\n",
        "\n",
        "<b> Rem 2</b> From just obtained formula it is clear that $dist_1(\\partial G,\\partial S)=|\\Delta S|$.\n",
        "\n",
        "Let us rewrite the above formula via integral over the whole region $\\Omega$\n",
        "\\begin{multline*}\n",
        "(dist_k(\\partial G, \\partial S))^k = k\\left(\\int_{S\\setminus G}D^{k-1}_G(x)\\,dx+\\int_{G\\setminus S}D^{k-1}_G(x)\\,dx\\right)=\\\\ \n",
        "k\\left(\\int_{S\\setminus G}D^{k-1}_G(x)\\,dx-\\int_{S\\cap G}D^{k-1}_G(x)\\,dx\\right)+k\\left(\\int_{S\\cap G}D^{k-1}_G(x)\\,dx+\\int_{G\\setminus S}D^{k-1}_G(x)\\,dx\\right)=\\\\\n",
        "k\\left(\\int_{S\\setminus G}D^{k-1}_G(x)\\,dx-\\int_{S\\cap G}D^{k-1}_G(x)\\,dx\\right)-k\\left(-\\int_{S\\cap G}D^{k-1}_G(x)\\,dx-\\int_{G\\setminus S}D^{k-1}_G(x)\\,dx\\right).\n",
        "\\end{multline*}\n",
        "\n",
        "Introducing the function $\\phi_G(x)$ (can be precomputed)\n",
        "\\begin{equation*}\n",
        "\\phi_G(x) =\n",
        "\\begin{cases}\n",
        "kD^{k-1}_G(x),\\ x\\notin G,\\\\\n",
        "-kD^{k-1}_G(x),\\ x\\in G,\n",
        "\\end{cases}\n",
        "\\end{equation*}\n",
        "\n",
        "we find\n",
        "\\begin{multline*}\n",
        "(dist_k(\\partial G, \\partial S))^k = \\int_S\\phi_G(x)\\,dx - \\int_G\\phi_G(x)\\,dx =\\\\ \\int_\\Omega \\phi_G(x)1_S(x)\\,dx - \\int_\\Omega \\phi_G(x)1_G(x)\\,dx= \\int_\\Omega\\phi_G(x)(1_S(x)-1_G(x))\\,dx, \n",
        "\\end{multline*}\n",
        "\n",
        "that is \n",
        "\n",
        "\\begin{equation*}\n",
        "(dist_k(\\partial G, \\partial S))^k = \\int_\\Omega\\phi_G(x)(1_S(x)-1_G(x))\\,dx. \n",
        "\\end{equation*}\n",
        "\n",
        "\n",
        "\n",
        "<b>Rem 3</b> We also have\n",
        "\\begin{equation*}\n",
        "(dist_k(\\partial G, \\partial S))^k \\leq k\\int_{\\Omega}D^{k-1}_G(x)|1_S(x)-1_G(x)|^\\alpha\\,dx,\\ \\mbox{for all }\\alpha\\geq 0.\n",
        "\\end{equation*}\n",
        "Indeed, for any $\\alpha\\geq 0$ we have\n",
        "\\begin{multline*}\n",
        "(dist_k(\\partial G, \\partial S))^k = k\\left(\\int_{S\\setminus G}D^{k-1}_G(x)\\,dx+\\int_{G\\setminus S}D^{k-1}_G(x)\\,dx\\right)=\\\\\n",
        "k\\left(\\int_{S\\setminus G}D^{k-1}_G(x)(1_S(x)-1_G(x))\\,dx+\\int_{G\\setminus S}D^{k-1}_G(x)(1_G(x)-1_S(x))\\,dx\\right)=\\\\\n",
        "k\\int_{S\\Delta G}D^{k-1}_G(x)|1_S(x)-1_G(x)|^\\alpha\\,dx\\leq k\\int_{\\Omega}D^{k-1}_G(x)|1_S(x)-1_G(x)|^\\alpha\\,dx.\n",
        "\\end{multline*}\n",
        "\n",
        "<b>Rem 4</b> We can get rid of $\\phi_G(x)$ in $dist_k(\\partial G, \\partial S)$. This also shows a connection to some other losses considered in the literature.\n",
        "\\begin{multline*}\n",
        "(dist_k(\\partial G, \\partial S))^k = \\int_\\Omega\\phi_G(x)(1_S(x)-1_G(x))\\,dx = \\\\\n",
        "\\int_{\\Omega\\setminus G}\\phi_G(x)(1_S(x)-1_G(x))\\,dx + \\int_G\\phi_G(x)(1_S(x)-1_G(x))\\,dx=\\\\\n",
        "k\\int_{\\Omega\\setminus G}D^{k-1}_G(x)1_S(x)\\,dx +k\\int_G D^{k-1}_G(x)(1_G(x)-1_S(x))\\,dx =\\\\\n",
        "\\Big|1_S(x)= |1_G(x)-1_S(x)|,\\ x\\in\\Omega\\setminus G\\Big|=\n",
        "k\\int_\\Omega D_G^{k-1}(x)|1_G(x)-1_S(x)|dx, \n",
        "\\end{multline*}\n",
        "that is\n",
        "\\begin{equation*}\n",
        "(dist_k(\\partial G, \\partial S))^k = k\\int_\\Omega D_G^{k-1}(x)|1_G(x)-1_S(x)|dx. \n",
        "\\end{equation*}\n",
        "\n",
        "In the case the predicted segmentation mask $S$ is given in the form of probability density $p_{S}(x)$ the natural generalization of the above boundary loss is\n",
        "\\begin{equation*}\n",
        "Loss_k(\\theta) = (dist_k(\\partial G, \\partial S_\\theta))^k =  k\\int_{\\Omega}D^{k-1}_G(x)|1_G(x)-p_{S_\\theta}(x)|\\,dx.\n",
        "\\end{equation*}\n",
        "We implement the loss in just computed form. \n",
        "\n",
        "<b>Rem 5</b> Now the form for two-sided Hausdorff distance and its possible variants is clear \n",
        "\n",
        "\\begin{equation*}\n",
        "SymLoss_k(\\theta) = (dist^{sym}_k(\\partial G, \\partial S_\\theta))^k = max \\Big\\{k\\int_{\\Omega}D^{k-1}_G(x)|1_G(x)-p_{S_\\theta}(x)|\\,dx, k\\int_{\\Omega}D^{k-1}_{S_\\theta}(x)|1_G(x)-p_{S_\\theta}(x)|\\,dx\\Big\\},\n",
        "\\end{equation*}\n",
        "\n",
        "\\begin{multline*}\n",
        "SumLoss_k(\\theta) = (dist_k(\\partial G, \\partial S_\\theta))^k+ (dist_k(\\partial S_\\theta,\\partial G))^k=\\\\\n",
        "k\\int_{\\Omega}D^{k-1}_G(x)|1_G(x)-p_{S_\\theta}(x)|\\,dx + k\\int_{\\Omega}D^{k-1}_{S_\\theta}(x)|1_G(x)-p_{S_\\theta}(x)|\\,dx.\n",
        "\\end{multline*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW4z4YUnM2Mo"
      },
      "source": [
        "# IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRH9zupy3cLr"
      },
      "source": [
        "# Catalyst\r\n",
        "!pip install catalyst==20.12 &> /dev/null\r\n",
        "# for pretrained segmentation models for PyTorch\r\n",
        "!pip install segmentation-models-pytorch==0.1.0 &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G_Tydij1bzY"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch import Tensor\n",
        "from scipy.ndimage import distance_transform_edt as distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO6jBeSp1bza"
      },
      "source": [
        "### Distance to the boundary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvYIHvqw1bza"
      },
      "source": [
        "# function $kD_G^{k-1}(x)$, can be precomputed for true mask\n",
        "def dist_2segbdry(seg: Tensor, k=2)->Tensor:\n",
        "    \"\"\"\n",
        "        seg - Tensor of shape \n",
        "                (b,c,h,w) if dim = 2\n",
        "                (b,c,h,w,d) if dim = 3.\n",
        "              consists of 0s and 1s, 1s correspond to the segmentation mask  \n",
        "        \n",
        "        this function may accept a method or argument that determines how to \n",
        "        calculate the distance transform. In general it is not necessarily\n",
        "        the euclidian distance transform from scipy, which is implemented now.\n",
        "    \"\"\"\n",
        "    \n",
        "    B, C = seg.shape[:2]\n",
        "    \n",
        "    res = torch.zeros_like(seg)\n",
        "    \n",
        "    # mask for the actual segmentaion\n",
        "    posmask = seg.bool().cpu()\n",
        "    # mask for the complement to the segmentation mask\n",
        "    negmask = ~posmask\n",
        "    \n",
        "    # there is no option \"along axis\" for distance_transform_edt so we iterate \n",
        "    for b in range(B):\n",
        "        for c in range(C):\n",
        "            #            dist^{k-1}(x, bdry seg), x outside seg              dist^{k-1}(x, bdry seg), x inside seg     \n",
        "            res[b,c] = k*( negmask[b,c]*(distance(negmask[b,c])**(k-1)) + posmask[b,c]*(distance(posmask[b,c])**(k-1)) )\n",
        "            # here distance - computes distances from 1s to 0s - see the check below \n",
        "    \n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa9m4o4x1bzb"
      },
      "source": [
        "class Dist_2SegBdry(nn.Module):\n",
        "    \"\"\"\n",
        "        calculates the distance to the segmentation mask bdry\n",
        "        see the detailed description for the fn dist_2segbdry\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(Dist_2SegBdry, self).__init__()\n",
        "    def forward(seg: Tensor, k=2)->Tensor:\n",
        "        return dist_2segbdry(seg, k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym9PuSlq1bzb"
      },
      "source": [
        "### Distance check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "ZzTtY8tT1bzc"
      },
      "source": [
        "a = Tensor(\n",
        "    [\n",
        "        [\n",
        "            [[1,0],[1,1]],\n",
        "            [[1,1],[1,1]],\n",
        "            [[1,1],[1,1]]\n",
        "            \n",
        "        ],\n",
        "        [\n",
        "            [[1,1],[0,1]],\n",
        "            [[1,1],[0,1]],\n",
        "            [[1,1],[0,1]]\n",
        "        ]\n",
        "    ]\n",
        ")\n",
        "print(a.shape)\n",
        "b = distance(a)\n",
        "print(b.shape)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvFqXsVs1bzc"
      },
      "source": [
        "### Boundary Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrw7THa91bzd"
      },
      "source": [
        "def bdry_loss(other_seg: Tensor, seg: Tensor, dt_seg: Tensor = None, k=2):\n",
        "    \"\"\"\n",
        "        all input tesors have the same shape: \n",
        "            (b,c,h,w) if dim = 2,\n",
        "            (b,c,h,w,d) if dim = 3.\n",
        "            \n",
        "        seg - true_mask, consists of 0s and 1s,\n",
        "        \n",
        "        other_seg - predicted segmentation\n",
        "                    can be soft (tensor of probabilities) or hard (tensor of 0s and 1s)\n",
        "        \n",
        "        dt_seg - precomputed dist_2segbdry(seg,k), preferred to seg\n",
        "        dt - for distance transform, in general it is not neccessarily\n",
        "                  given by distance_transform_edt from scipy but can be a different one,\n",
        "                  for example based on colnvolutions, erosions or use a different metric\n",
        "        \n",
        "        each channel c corresponds to one class\n",
        "        1s corresponds to the segmentation mask, 0s - to the complement\n",
        "        k - distance degree\n",
        "    \"\"\"\n",
        "    if dt_seg is not None:\n",
        "        assert dt_seg.shape == other_seg.shape\n",
        "        return (dt_seg*torch.abs(other_seg-seg)).mean()\n",
        "    else:\n",
        "        assert seg.shape == other_seg.shape\n",
        "        return (dist_2segbdry(seg, k)*torch.abs(other_seg-seg)).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqiwfanE1bzd"
      },
      "source": [
        "class BdryLoss(nn.Module):\n",
        "    \"\"\"\n",
        "        Calculates the bdry loss\n",
        "        See the detailed description for the fn bdry_loss\n",
        "    \"\"\"\n",
        "    def __init__(self, k: int = 2, eps: float = 1e-9, dt_seg: Tensor = None):\n",
        "        super(BdryLoss, self).__init__()\n",
        "        self.eps = eps\n",
        "        self.k=k\n",
        "        self.dt_seg = dt_seg\n",
        "    def forward(self, other_seg: Tensor, seg: Tensor):\n",
        "        return bdry_loss(other_seg = torch.sigmoid(other_seg), seg = seg, dt_seg = self.dt_seg, k=self.k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7LJbMai1bze"
      },
      "source": [
        "### Symmetric Boundary Loss: via max"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-dESjvE1bze"
      },
      "source": [
        "def sym_bdry_loss(other_seg: Tensor, seg: Tensor, dt_seg: Tensor = None,  k=2):\n",
        "    \"\"\"\n",
        "        all input tesors have the same shape: \n",
        "            (b,c,h,w) if dim = 2,\n",
        "            (b,c,h,w,d) if dim = 3.\n",
        "        \n",
        "        seg - true_mask, consists of 0s and 1s;\n",
        "        \n",
        "        \n",
        "        other_seg - predicted segmentation,\n",
        "                    can be soft (tensor of probabilities) or hard (tensor of 0s and 1s)\n",
        "                    \n",
        "        dt_seg - precomputed dist_2segbdry(seg,k) \n",
        "        \n",
        "        each channel c corresponds to one class\n",
        "        1s corresponds to the segmentation mask, 0 - to the complement\n",
        "        k - distance degree\n",
        "    \"\"\"\n",
        "    \n",
        "    if not dt_seg:\n",
        "        dt_seg = dist_2segbdry(seg, k)\n",
        "\n",
        "    assert dt_seg.shape == other_seg.shape and seg.shape == other_seg.shape\n",
        "    \n",
        "    # other_seg_01 - the tensor of probabilities mapped to 01-tensor\n",
        "    # may be useful to make thresholds for each channel\n",
        "    other_seg_01 = (other_seg>0.5).int()\n",
        "    \n",
        "    return np.max([bdry_loss(other_seg = other_seg, seg = seg, dt_seg = dt_seg),\n",
        "                   bdry_loss(seg = other_seg_01, other_seg = seg)]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHZwy4VB1bzf"
      },
      "source": [
        "class SymBdryLoss(nn.Module):\n",
        "    \"\"\"\n",
        "        Calculates symmetric boundary loss via max\n",
        "        See the detailed description for the fn sym_bdry_loss\n",
        "    \"\"\"\n",
        "    def __init__(self, k: int = 2, eps: float = 1e-9, dt_seg: Tensor = None):\n",
        "        super(SymBdryLoss, self).__init__()\n",
        "        self.k = k\n",
        "        self.eps = eps\n",
        "        self.dt_seg = dt_seg\n",
        "    def forward(self, other_seg: Tensor, seg: Tensor):\n",
        "        return sym_bdry_loss(other_seg = torch.sigmoid(other_seg), seg = seg, dt_seg = self.dt_seg, k=self.k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPUjuJHE1bzf"
      },
      "source": [
        "### Symmetric Boundary Loss: via sum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzJ5SUk11bzg"
      },
      "source": [
        "def sum_bdry_loss(other_seg: Tensor, seg: Tensor, dt_seg: Tensor = None,  k=2):\n",
        "    \"\"\"\n",
        "        all input tesors have the same shape: \n",
        "            (b,c,h,w) if dim = 2,\n",
        "            (b,c,h,w,d) if dim = 3.\n",
        "        \n",
        "        seg - true_mask, consists of 0s and 1s;\n",
        "        \n",
        "        other_seg - predicted segmentation,\n",
        "                    can be soft (tensor of probabilities) or hard (tensor of 0s and 1s);\n",
        "                    \n",
        "        dt_seg - precomputed dist_2segbdry(seg,k); \n",
        "        \n",
        "        each channel c corresponds to one class\n",
        "        1s corresponds to the segmentation mask, 0 - to the complement\n",
        "        k - distance degree\n",
        "    \"\"\"\n",
        "\n",
        "    if not dt_seg:\n",
        "        dt_seg = dist_2segbdry(seg, k)\n",
        "\n",
        "    assert dt_seg.shape == other_seg.shape and seg.shape == other_seg.shape\n",
        "    \n",
        "    # other_seg_01 - the tensor of probabilities mapped to 01-tensor\n",
        "    # may be useful to make thresholds for each channel\n",
        "    other_seg_01 = (other_seg>0.5).int()\n",
        "    \n",
        "    return bdry_loss(other_seg = other_seg, seg = seg, dt_seg = dt_seg) + \\\n",
        "            bdry_loss(seg = other_seg_01, other_seg = seg) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjDlDIHU1bzg"
      },
      "source": [
        "class SumBdryLoss(nn.Module):\n",
        "    \"\"\"\n",
        "        Calculate sum_bdry_loss\n",
        "        See the detailed description for the fn sum_bdry_loss\n",
        "    \"\"\"\n",
        "    def __init__(self, k: int = 2, eps: float = 1e-9, dt_seg: Tensor = None):\n",
        "        super(SumBdryLoss, self).__init__()\n",
        "        self.k = k\n",
        "        self.eps = eps\n",
        "        self.dt_seg = dt_seg\n",
        "    def forward(self, other_seg: Tensor, seg: Tensor):\n",
        "        return sum_bdry_loss(other_seg = torch.sigmoid(other_seg), seg = seg, dt_seg = self.dt_seg, k=self.k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjZGX4ij3XgZ"
      },
      "source": [
        "# TRAIN EXAMPLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfbe6ItYbaT8"
      },
      "source": [
        "from catalyst.dl.callbacks import MetricCallback\r\n",
        "\r\n",
        "class SumBdryCallback(MetricCallback):\r\n",
        "    \"\"\"\r\n",
        "    sum_bdry_loss metric callback.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(\r\n",
        "        self,\r\n",
        "        input_key: str = \"targets\",\r\n",
        "        output_key: str = \"logits\",\r\n",
        "        prefix: str = \"bndry\",\r\n",
        "        eps: float = 1e-7,\r\n",
        "        threshold: float = None,\r\n",
        "        activation: str = \"Sigmoid\"\r\n",
        "    ):\r\n",
        "        \"\"\"\r\n",
        "        :param input_key: input key to use for boundary loss calculation;\r\n",
        "            specifies our `y_true`.\r\n",
        "        :param output_key: output key to use for boundary loss calculation;\r\n",
        "            specifies our `y_pred`.\r\n",
        "        \"\"\"\r\n",
        "        super().__init__(\r\n",
        "            prefix=prefix,\r\n",
        "            metric_fn=sum_bdry_loss,\r\n",
        "            input_key=input_key,\r\n",
        "            output_key=output_key,\r\n",
        "            eps=eps,\r\n",
        "            threshold=threshold,\r\n",
        "            activation=activation\r\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcaGHvgxEvWp"
      },
      "source": [
        "## Install & import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVKCtYzt8K2v"
      },
      "source": [
        "from typing import Callable, List, Tuple\r\n",
        "\r\n",
        "from os import listdir\r\n",
        "from os.path import join\r\n",
        "\r\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWR-XSbfEpeB"
      },
      "source": [
        "## Setting up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvO-dXSDFHlC"
      },
      "source": [
        "is_fp16_used = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1kuPGsaErU5"
      },
      "source": [
        "from catalyst import utils\r\n",
        "SEED = 42\r\n",
        "utils.set_global_seed(SEED)\r\n",
        "utils.prepare_cudnn(deterministic=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQDNdRQnEazf"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV-Qt_xA3ea8"
      },
      "source": [
        "%%bash\r\n",
        "\r\n",
        "download-gdrive 1Ka-_ehIYoSb7PsR_NxNvJqmEe_NuHYC_ chest-ct-segmentation.zip &> /dev/null\r\n",
        "extract-archive chest-ct-segmentation.zip &>/dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvI-vGy96MrB"
      },
      "source": [
        "from pathlib import Path, PosixPath\r\n",
        "\r\n",
        "ROOT = Path(\"\")\r\n",
        "\r\n",
        "train_image_path = ROOT / \"images/images\"\r\n",
        "train_mask_path = ROOT / \"masks/masks\"\r\n",
        "test_image_path = ROOT / \"images/images\"\r\n",
        "test_mask_path = ROOT / \"masks/masks\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO0bIrtA9xwY"
      },
      "source": [
        "all_image_filenames = listdir(train_image_path)\r\n",
        "train_image_filenames = all_image_filenames[:-100]\r\n",
        "test_image_filenames = all_image_filenames[-100:]\r\n",
        "\r\n",
        "mask_filenames = [f.replace('_mask', '') for f in listdir(train_mask_path)]\r\n",
        "\r\n",
        "train_intersect = set(mask_filenames).intersection(train_image_filenames)\r\n",
        "TRAIN_IMAGES = sorted([PosixPath(join(train_image_path, f)) for f in train_intersect])\r\n",
        "TRAIN_MASKS = sorted([PosixPath(join(train_mask_path, f[:26] + 'mask_' + f[26:])) for f in train_intersect])\r\n",
        "\r\n",
        "test_intersect = set(mask_filenames).intersection(test_image_filenames)\r\n",
        "TEST_IMAGES = sorted([PosixPath(join(test_image_path, f)) for f in test_intersect])\r\n",
        "TEST_MASKS = sorted([PosixPath(join(test_mask_path, f[:26] + 'mask_' + f[26:])) for f in test_intersect])\r\n",
        "\r\n",
        "print(len(TRAIN_IMAGES))\r\n",
        "print(len(TRAIN_MASKS))\r\n",
        "print(len(TEST_IMAGES))\r\n",
        "print(len(TEST_IMAGES))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBCn3gao7s8s"
      },
      "source": [
        "import random\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "from skimage.io import imread as gif_imread\r\n",
        "from catalyst import utils\r\n",
        "\r\n",
        "\r\n",
        "def show_examples(name: str, image: np.ndarray, mask: np.ndarray, gt=None):\r\n",
        "    plt.figure(figsize=(15, 14))\r\n",
        "    plt.subplot(1, 3, 1)\r\n",
        "    plt.imshow(image)\r\n",
        "    plt.title(f\"Image: {name}\")\r\n",
        "\r\n",
        "    plt.subplot(1, 3, 2)\r\n",
        "    plt.imshow(mask)\r\n",
        "    plt.title(f\"Mask: {name}\")\r\n",
        "\r\n",
        "    if gt is not None:\r\n",
        "        plt.subplot(1, 3, 3)\r\n",
        "        plt.imshow(gt)\r\n",
        "        plt.title(f\"Ground truth: {name}\")\r\n",
        "\r\n",
        "def show(index: int, images: List[Path], masks: List[Path], transforms=None) -> None:\r\n",
        "    image_path = images[index]\r\n",
        "    name = image_path.name\r\n",
        "    print(image_path)\r\n",
        "    print(masks[index])\r\n",
        "\r\n",
        "    image = utils.imread(image_path)\r\n",
        "    mask = utils.imread(masks[index])[:,:,0]\r\n",
        "\r\n",
        "    if transforms is not None:\r\n",
        "        temp = transforms(image=image, mask=mask)\r\n",
        "        image = temp[\"image\"]\r\n",
        "        mask = temp[\"mask\"]\r\n",
        "\r\n",
        "    show_examples(name, image, mask)\r\n",
        "\r\n",
        "def show_random(images: List[Path], masks: List[Path], transforms=None) -> None:\r\n",
        "    length = len(images)\r\n",
        "    index = random.randint(0, length - 1)\r\n",
        "    show(index, images, masks, transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw6521jXMxTA"
      },
      "source": [
        "show_random(TRAIN_IMAGES, TRAIN_MASKS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEw0S0-b76jm"
      },
      "source": [
        "image = utils.imread('images/images/ID00009637202177434476278_338.jpg')\r\n",
        "mask = utils.imread('masks/masks/ID00009637202177434476278_mask_338.jpg')[:,:,0]\r\n",
        "show_examples('ID00009637202177434476278_338', image, mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI_pqgSJ8Oiz"
      },
      "source": [
        "from typing import List\r\n",
        "\r\n",
        "from torch.utils.data import Dataset\r\n",
        "\r\n",
        "\r\n",
        "class SegmentationDataset(Dataset):\r\n",
        "    def __init__(\r\n",
        "        self,\r\n",
        "        images: List[Path],\r\n",
        "        masks: List[Path] = None,\r\n",
        "        transforms=None\r\n",
        "    ) -> None:\r\n",
        "        self.images = images\r\n",
        "        self.masks = masks\r\n",
        "        self.transforms = transforms\r\n",
        "\r\n",
        "    def __len__(self) -> int:\r\n",
        "        return len(self.images)\r\n",
        "\r\n",
        "    def __getitem__(self, idx: int) -> dict:\r\n",
        "        image_path = self.images[idx]\r\n",
        "        image = utils.imread(image_path)\r\n",
        "        \r\n",
        "        result = {\"image\": image}\r\n",
        "        \r\n",
        "        if self.masks is not None:\r\n",
        "            mask = utils.imread(self.masks[idx])[:,:,0]\r\n",
        "            result[\"mask\"] = mask\r\n",
        "        \r\n",
        "        if self.transforms is not None:\r\n",
        "            result = self.transforms(**result)\r\n",
        "        \r\n",
        "        result[\"filename\"] = image_path.name\r\n",
        "\r\n",
        "        return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuHWLMQQCTKx"
      },
      "source": [
        "## Albumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y52kS5DBBwor"
      },
      "source": [
        "import albumentations as albu\n",
        "from albumentations.pytorch import ToTensor\n",
        "\n",
        "# Which we want to use?\n",
        "\n",
        "def pre_transforms(image_size=224):\n",
        "    return [albu.Resize(image_size, image_size, p=1)]\n",
        "\n",
        "\n",
        "def hard_transforms():\n",
        "    result = [\n",
        "      albu.RandomRotate90(),\n",
        "      albu.Cutout(),\n",
        "      albu.RandomBrightnessContrast(\n",
        "          brightness_limit=0.2, contrast_limit=0.2, p=0.3\n",
        "      ),\n",
        "      albu.GridDistortion(p=0.3),\n",
        "      albu.HueSaturationValue(p=0.3)\n",
        "    ]\n",
        "\n",
        "    return result\n",
        "  \n",
        "\n",
        "def resize_transforms(image_size=224):\n",
        "    BORDER_CONSTANT = 0\n",
        "    pre_size = int(image_size * 1.5)\n",
        "\n",
        "    random_crop = albu.Compose([\n",
        "      albu.SmallestMaxSize(pre_size, p=1),\n",
        "      albu.RandomCrop(\n",
        "          image_size, image_size, p=1\n",
        "      )\n",
        "\n",
        "    ])\n",
        "\n",
        "    rescale = albu.Compose([albu.Resize(image_size, image_size, p=1)])\n",
        "\n",
        "    random_crop_big = albu.Compose([\n",
        "      albu.LongestMaxSize(pre_size, p=1),\n",
        "      albu.RandomCrop(\n",
        "          image_size, image_size, p=1\n",
        "      )\n",
        "\n",
        "    ])\n",
        "\n",
        "    # Converts the image to a square of size image_size x image_size\n",
        "    result = [\n",
        "      albu.OneOf([\n",
        "          random_crop,\n",
        "          rescale,\n",
        "          random_crop_big\n",
        "      ], p=1)\n",
        "    ]\n",
        "\n",
        "    return result\n",
        "  \n",
        "def post_transforms():\n",
        "    # we use ImageNet image normalization\n",
        "    # and convert it to torch.Tensor\n",
        "    return [albu.Normalize(), ToTensor()]\n",
        "  \n",
        "def compose(transforms_to_compose):\n",
        "    # combine all augmentations into single pipeline\n",
        "    result = albu.Compose([\n",
        "      item for sublist in transforms_to_compose for item in sublist\n",
        "    ])\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1LKymhFCbsw"
      },
      "source": [
        "train_transforms = compose([\r\n",
        "    resize_transforms(), \r\n",
        "    hard_transforms(), \r\n",
        "    post_transforms()\r\n",
        "])\r\n",
        "valid_transforms = compose([pre_transforms(), post_transforms()])\r\n",
        "\r\n",
        "show_transforms = compose([resize_transforms(), hard_transforms()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmGt4gFNCdVP"
      },
      "source": [
        "show_random(TRAIN_IMAGES, TRAIN_MASKS, transforms=show_transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j7HH4ZgE1rx"
      },
      "source": [
        "## Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kEIQxPrCoE3"
      },
      "source": [
        "import collections\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "def get_loaders(\r\n",
        "    images: List[Path],\r\n",
        "    masks: List[Path],\r\n",
        "    random_state: int,\r\n",
        "    valid_size: float = 0.2,\r\n",
        "    batch_size: int = 32,\r\n",
        "    num_workers: int = 4,\r\n",
        "    train_transforms_fn = None,\r\n",
        "    valid_transforms_fn = None,\r\n",
        ") -> dict:\r\n",
        "\r\n",
        "    indices = np.arange(len(images))\r\n",
        "\r\n",
        "    # Let's divide the data set into train and valid parts.\r\n",
        "    train_indices, valid_indices = train_test_split(\r\n",
        "      indices, test_size=valid_size, random_state=random_state, shuffle=True\r\n",
        "    )\r\n",
        "\r\n",
        "    np_images = np.array(images)\r\n",
        "    np_masks = np.array(masks)\r\n",
        "\r\n",
        "    # Creates our train dataset\r\n",
        "    train_dataset = SegmentationDataset(\r\n",
        "      images = np_images[train_indices].tolist(),\r\n",
        "      masks = np_masks[train_indices].tolist(),\r\n",
        "      transforms = train_transforms_fn\r\n",
        "    )\r\n",
        "\r\n",
        "    # Creates our valid dataset\r\n",
        "    valid_dataset = SegmentationDataset(\r\n",
        "      images = np_images[valid_indices].tolist(),\r\n",
        "      masks = np_masks[valid_indices].tolist(),\r\n",
        "      transforms = valid_transforms_fn\r\n",
        "    )\r\n",
        "\r\n",
        "    # Catalyst uses normal torch.data.DataLoader\r\n",
        "    train_loader = DataLoader(\r\n",
        "      train_dataset,\r\n",
        "      batch_size=batch_size,\r\n",
        "      shuffle=True,\r\n",
        "      num_workers=num_workers,\r\n",
        "      drop_last=True,\r\n",
        "    )\r\n",
        "\r\n",
        "    valid_loader = DataLoader(\r\n",
        "      valid_dataset,\r\n",
        "      batch_size=batch_size,\r\n",
        "      shuffle=False,\r\n",
        "      num_workers=num_workers,\r\n",
        "      drop_last=True,\r\n",
        "    )\r\n",
        "\r\n",
        "    # And excpect to get an OrderedDict of loaders\r\n",
        "    loaders = collections.OrderedDict()\r\n",
        "    loaders[\"train\"] = train_loader\r\n",
        "    loaders[\"valid\"] = valid_loader\r\n",
        "\r\n",
        "    return loaders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcZB3GCdE8aZ"
      },
      "source": [
        "if is_fp16_used:\r\n",
        "    batch_size = 64\r\n",
        "else:\r\n",
        "    batch_size = 32\r\n",
        "\r\n",
        "print(f\"batch_size: {batch_size}\")\r\n",
        "\r\n",
        "loaders = get_loaders(\r\n",
        "    images=TRAIN_IMAGES,\r\n",
        "    masks=TRAIN_MASKS,\r\n",
        "    random_state=SEED,\r\n",
        "    train_transforms_fn=train_transforms,\r\n",
        "    valid_transforms_fn=valid_transforms,\r\n",
        "    batch_size=batch_size\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAJCRMekFpGt"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN_2vsxcFtAp"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97hBwqTbFAew"
      },
      "source": [
        "import segmentation_models_pytorch as smp\r\n",
        "\r\n",
        "# We will use Feature Pyramid Network with pre-trained ResNeXt50 backbone\r\n",
        "model = smp.FPN(encoder_name=\"resnext50_32x4d\", classes=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7A1xTmfHN5S"
      },
      "source": [
        "### Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7Dj1ghBFuJR"
      },
      "source": [
        "from torch import nn\r\n",
        "\r\n",
        "from catalyst.contrib.nn import DiceLoss, IoULoss\r\n",
        "\r\n",
        "# we have multiple criterions\r\n",
        "criterion = {\r\n",
        "    \"dice\": DiceLoss(),\r\n",
        "    \"iou\": IoULoss(),\r\n",
        "    \"bce\": nn.BCEWithLogitsLoss(),\r\n",
        "    \"sum_bndry\": SumBdryLoss(),\r\n",
        "    \"sym_bndry\": SymBdryLoss(),\r\n",
        "    \"bndry\": BdryLoss()\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9fRnbyoG5kk"
      },
      "source": [
        "from torch import optim\r\n",
        "\r\n",
        "from catalyst.contrib.nn import RAdam, Lookahead\r\n",
        "\r\n",
        "learning_rate = 0.001\r\n",
        "encoder_learning_rate = 0.0005\r\n",
        "\r\n",
        "# Since we use a pre-trained encoder, we will reduce the learning rate on it.\r\n",
        "layerwise_params = {\"encoder*\": dict(lr=encoder_learning_rate, weight_decay=0.00003)}\r\n",
        "\r\n",
        "# This function removes weight_decay for biases and applies our layerwise_params\r\n",
        "model_params = utils.process_model_params(model, layerwise_params=layerwise_params)\r\n",
        "\r\n",
        "# Catalyst has new SOTA optimizers out of box\r\n",
        "base_optimizer = RAdam(model_params, lr=learning_rate, weight_decay=0.0003)\r\n",
        "optimizer = Lookahead(base_optimizer)\r\n",
        "\r\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.25, patience=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kOM6pMOBLpR"
      },
      "source": [
        "from catalyst.callbacks import MetricCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsDZBwVrG8T5"
      },
      "source": [
        "from catalyst.dl import SupervisedRunner\r\n",
        "\r\n",
        "num_epochs = 3\r\n",
        "logdir = \"./logs/segmentation\"\r\n",
        "\r\n",
        "device = utils.get_device()\r\n",
        "print(f\"device: {device}\")\r\n",
        "\r\n",
        "if is_fp16_used:\r\n",
        "    fp16_params = dict(opt_level=\"O1\") # params for FP16\r\n",
        "else:\r\n",
        "    fp16_params = None\r\n",
        "\r\n",
        "print(f\"FP16 params: {fp16_params}\")\r\n",
        "\r\n",
        "\r\n",
        "# by default SupervisedRunner uses \"features\" and \"targets\",\r\n",
        "# in our case we get \"image\" and \"mask\" keys in dataset __getitem__\r\n",
        "runner = SupervisedRunner(device=device, input_key=\"image\", input_target_key=\"mask\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpa_I-nTHH2g"
      },
      "source": [
        "### Running train-loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbP9TvlDG-iA"
      },
      "source": [
        "from catalyst.dl import DiceCallback, IouCallback, \\\r\n",
        "  CriterionCallback, MetricAggregationCallback\r\n",
        "from catalyst.contrib.callbacks import DrawMasksCallback\r\n",
        "\r\n",
        "base_callbacks = [\r\n",
        "    # Each criterion is calculated separately.\r\n",
        "    CriterionCallback(\r\n",
        "        input_key=\"mask\",\r\n",
        "        prefix=\"loss_dice\",\r\n",
        "        criterion_key=\"dice\"\r\n",
        "    ),\r\n",
        "    CriterionCallback(\r\n",
        "        input_key=\"mask\",\r\n",
        "        prefix=\"loss_iou\",\r\n",
        "        criterion_key=\"iou\"\r\n",
        "    ),\r\n",
        "    CriterionCallback(\r\n",
        "        input_key=\"mask\",\r\n",
        "        prefix=\"loss_bce\",\r\n",
        "        criterion_key=\"bce\"\r\n",
        "    ),\r\n",
        "    CriterionCallback(\r\n",
        "        input_key=\"mask\",\r\n",
        "        prefix=\"loss_sum_bndry\",\r\n",
        "        criterion_key=\"sum_bndry\"\r\n",
        "    ),\r\n",
        "    CriterionCallback(\r\n",
        "        input_key=\"mask\",\r\n",
        "        prefix=\"loss_sym_bndry\",\r\n",
        "        criterion_key=\"sym_bndry\"\r\n",
        "    ),\r\n",
        "    CriterionCallback(\r\n",
        "        input_key=\"mask\",\r\n",
        "        prefix=\"loss_bndry\",\r\n",
        "        criterion_key=\"bndry\"\r\n",
        "    ),\r\n",
        "\r\n",
        "    # metrics\r\n",
        "    DiceCallback(input_key=\"mask\", threshold=0.5),\r\n",
        "    IouCallback(input_key=\"mask\", threshold=0.5),\r\n",
        "    # visualization\r\n",
        "    DrawMasksCallback(output_key='logits',\r\n",
        "                      input_image_key='image',\r\n",
        "                      input_mask_key='mask',\r\n",
        "                      summary_step=50\r\n",
        "    )\r\n",
        "]\r\n",
        "\r\n",
        "callbacks = base_callbacks + [\r\n",
        "    # And only then we aggregate everything into one loss.\r\n",
        "    MetricAggregationCallback(\r\n",
        "        prefix=\"loss\",\r\n",
        "        mode=\"weighted_sum\", # can be \"sum\", \"weighted_sum\" or \"mean\"\r\n",
        "        # because we want weighted sum, we need to add scale for each loss\r\n",
        "        metrics={\"loss_dice\": 1, \"loss_iou\": 0.0, \"loss_bce\": 0.0, \"loss_bndry\": 1.0, \"loss_sum_bndry\": 0.0, \"loss_sum_bndry\": 0.0},\r\n",
        "    )\r\n",
        "]\r\n",
        "\r\n",
        "'''\r\n",
        "runner.train(\r\n",
        "    model=model,\r\n",
        "    criterion=criterion,\r\n",
        "    optimizer=optimizer,\r\n",
        "    scheduler=scheduler,\r\n",
        "    # our dataloaders\r\n",
        "    loaders=loaders,\r\n",
        "    # We can specify the callbacks list for the experiment;\r\n",
        "    callbacks=callbacks,\r\n",
        "    # path to save logs\r\n",
        "    logdir=logdir,\r\n",
        "    num_epochs=num_epochs,\r\n",
        "    # save our best checkpoint by dice metric\r\n",
        "    main_metric=\"dice\",\r\n",
        "    # Dice needs to be maximized.\r\n",
        "    minimize_metric=False,\r\n",
        "    # for FP16. It uses the variable from the very first cell\r\n",
        "    fp16=fp16_params,\r\n",
        "    # prints train logs\r\n",
        "    verbose=True,\r\n",
        ")\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeYcrvbv-0T5"
      },
      "source": [
        "## Model inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPqp8fHPHDXo"
      },
      "source": [
        "'''\r\n",
        "# create test dataset\r\n",
        "test_dataset = SegmentationDataset(\r\n",
        "    TEST_IMAGES,\r\n",
        "    TEST_MASKS, \r\n",
        "    transforms=valid_transforms\r\n",
        ")\r\n",
        "\r\n",
        "num_workers: int = 4\r\n",
        "\r\n",
        "infer_loader = DataLoader(\r\n",
        "    test_dataset,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=False,\r\n",
        "    num_workers=num_workers\r\n",
        ")\r\n",
        "\r\n",
        "# this get predictions for the whole loader\r\n",
        "predictions = np.vstack(list(map(\r\n",
        "    lambda x: x[\"logits\"].cpu().numpy(), \r\n",
        "    runner.predict_loader(loader=infer_loader, resume=f\"{logdir}/checkpoints/best.pth\")\r\n",
        ")))\r\n",
        "\r\n",
        "print(type(predictions))\r\n",
        "print(predictions.shape)\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ULMZBg7_EzK"
      },
      "source": [
        "'''\r\n",
        "threshold = 0.5\r\n",
        "max_count = 100\r\n",
        "\r\n",
        "for i, (features, logits) in enumerate(zip(test_dataset, predictions)):\r\n",
        "    image = utils.tensor_to_ndimage(features[\"image\"])\r\n",
        "    gt = utils.tensor_to_ndimage(features[\"mask\"])\r\n",
        "\r\n",
        "    mask_ = torch.from_numpy(logits[0]).sigmoid()\r\n",
        "    mask = utils.detach(mask_ > threshold).astype(\"float\")\r\n",
        "        \r\n",
        "    show_examples(name=\"\", image=image, mask=mask, gt=gt)\r\n",
        "    \r\n",
        "    if i >= max_count:\r\n",
        "        break\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SPW1Wh0NlCO"
      },
      "source": [
        "# COMPARING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDUtqfx_R2ha"
      },
      "source": [
        "from catalyst.metrics.dice import dice\r\n",
        "from catalyst.metrics.iou import iou\r\n",
        "\r\n",
        "def calculate_test_scores(runner, comparison_results):\r\n",
        "\r\n",
        "    # Getting predictions\r\n",
        "\r\n",
        "    num_workers: int = 4\r\n",
        "\r\n",
        "    infer_loader = DataLoader(\r\n",
        "        test_dataset,\r\n",
        "        batch_size=batch_size,\r\n",
        "        shuffle=False,\r\n",
        "        num_workers=num_workers\r\n",
        "    )\r\n",
        "\r\n",
        "    predictions = np.vstack(list(map(\r\n",
        "        lambda x: x[\"logits\"].cpu().numpy(), \r\n",
        "        runner.predict_loader(loader=infer_loader, resume=f\"{logdir}/checkpoints/best.pth\")\r\n",
        "    )))\r\n",
        "\r\n",
        "    # Calculate scores\r\n",
        "\r\n",
        "    threshold = 0.5\r\n",
        "    dice_scores = []\r\n",
        "    iou_scores = []\r\n",
        "    bndry_scores = []\r\n",
        "    sum_bndry_scores = []\r\n",
        "    sym_bndry_scores = []\r\n",
        "\r\n",
        "    for i, (features, logits) in enumerate(zip(test_dataset, predictions)):\r\n",
        "        gt = features[\"mask\"][np.newaxis,:,:,:]\r\n",
        "\r\n",
        "        mask_ = torch.from_numpy(logits[0]).sigmoid()[np.newaxis, np.newaxis,:,:]\r\n",
        "        mask = (mask_ > threshold).float()\r\n",
        "            \r\n",
        "        dice_scores.append(dice(mask, gt)[0])\r\n",
        "        iou_scores.append(iou(mask, gt)[0])\r\n",
        "        bndry_scores.append(bdry_loss(mask, gt))\r\n",
        "        sum_bndry_scores.append(sum_bdry_loss(mask, gt))\r\n",
        "        sym_bndry_scores.append(sym_bdry_loss(mask, gt))\r\n",
        "    \r\n",
        "    comparison_results.append({\r\n",
        "        'dice': np.mean(dice_scores),\r\n",
        "        'iou': np.mean(iou_scores),\r\n",
        "        'bndry': np.mean(bndry_scores),\r\n",
        "        'sum_bndry': np.mean(sum_bndry_scores),\r\n",
        "        'sym_bndry': np.mean(sym_bndry_scores),\r\n",
        "    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYkYeIbkRRx-"
      },
      "source": [
        "## Running train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIDbyPas_Vqn"
      },
      "source": [
        "metrics_grid = [\r\n",
        "                {\"loss_dice\": 1.0, \"loss_bndry\": 0.0, \"loss_sum_bndry\": 0.0, \"loss_sym_bndry\": 0.0, \"loss_iou\": 0.0, \"loss_bce\": 0.0},\r\n",
        "                {\"loss_dice\": 1.0, \"loss_bndry\": 1.0, \"loss_sum_bndry\": 0.0, \"loss_sym_bndry\": 0.0, \"loss_iou\": 0.0, \"loss_bce\": 0.0},\r\n",
        "                {\"loss_dice\": 1.0, \"loss_bndry\": 0.0, \"loss_sum_bndry\": 1.0, \"loss_sym_bndry\": 0.0, \"loss_iou\": 0.0, \"loss_bce\": 0.0},\r\n",
        "                {\"loss_dice\": 1.0, \"loss_bndry\": 0.0, \"loss_sum_bndry\": 0.0, \"loss_sym_bndry\": 1.0, \"loss_iou\": 0.0, \"loss_bce\": 0.0},\r\n",
        "]\r\n",
        "\r\n",
        "comparison_results = []\r\n",
        "\r\n",
        "for metrics in metrics_grid:\r\n",
        "\r\n",
        "    print('=' * 100)\r\n",
        "    print('Training with {}'.format(metrics))\r\n",
        "\r\n",
        "    model = smp.FPN(encoder_name=\"resnext50_32x4d\", classes=1)\r\n",
        "\r\n",
        "    runner = SupervisedRunner(device=device, input_key=\"image\", input_target_key=\"mask\")\r\n",
        "\r\n",
        "    callbacks = base_callbacks + [\r\n",
        "        MetricAggregationCallback(\r\n",
        "            prefix=\"loss\",\r\n",
        "            mode=\"weighted_sum\", # can be \"sum\", \"weighted_sum\" or \"mean\"\r\n",
        "            metrics=metrics,\r\n",
        "        )\r\n",
        "    ]\r\n",
        "\r\n",
        "    runner.train(\r\n",
        "        model=model,\r\n",
        "        criterion=criterion,\r\n",
        "        optimizer=optimizer,\r\n",
        "        scheduler=scheduler,\r\n",
        "        # our dataloaders\r\n",
        "        loaders=loaders,\r\n",
        "        # We can specify the callbacks list for the experiment;\r\n",
        "        callbacks=callbacks,\r\n",
        "        # path to save logs\r\n",
        "        logdir=logdir,\r\n",
        "        num_epochs=num_epochs,\r\n",
        "        # save our best checkpoint by dice metric\r\n",
        "        main_metric=\"dice\",\r\n",
        "        # Dice needs to be maximized.\r\n",
        "        minimize_metric=False,\r\n",
        "        # for FP16. It uses the variable from the very first cell\r\n",
        "        fp16=fp16_params,\r\n",
        "        # prints train logs\r\n",
        "        verbose=True,\r\n",
        "    )\r\n",
        "\r\n",
        "    calculate_test_scores(runner, comparison_results)\r\n",
        "    \r\n",
        "    # Save current results\r\n",
        "    with open(\"/content/drive/MyDrive/segmentation_results.json\", \"w\") as f:\r\n",
        "        f.write(str(comparison_results))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wXzO2Z63Pza"
      },
      "source": [
        "comparison_results"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}